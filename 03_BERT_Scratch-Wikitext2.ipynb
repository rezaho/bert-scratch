{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a class=\"anchor\" id=\"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Imports](#imports)\n",
    "* [2. Utils](#utils)\n",
    "    * [2.1. GeLu](#gelu)\n",
    "    * [2.2. Layer Norm](#layer_norm)\n",
    "    * [2.3. Feed Forward](#feedforward)\n",
    "* [3. Attention](#attention)\n",
    "    * [3.1. Single Attention](#single_attention)\n",
    "    * [3.2. Multi-head Attention](#multihead_attention)\n",
    "* [4. Encoder Layer](#encoder)\n",
    "    * [4.1. Sublayer Connection](#sublayer)\n",
    "    * [4.2. Position-wise Feedforward](#position_feedforward)\n",
    "    * [4.3. Transformer Block](#transformer_block)\n",
    "* [5. Embeddings](#embeddings)\n",
    "    * [5.1. Token Embedding](#token_embedding)\n",
    "    * [5.2. Position Embedding](#position_embedding)\n",
    "    * [5.3. Segment Embedding](#segment_embedding)\n",
    "    * [5.3. BERT Embedding](#bert_embedding)\n",
    "* [6. Model](#model)\n",
    "    * [6.1. BERT](#bert)\n",
    "    * [6.2. Masked Language Model](#masked_lm)\n",
    "    * [6.3. Next Sentence Prediction](#nsp)\n",
    "    * [6.4. BERT Language Model](#bert_lm)\n",
    "\n",
    "* [7. Dataset](#dataset)\n",
    "    * [7.1. Vocabulary Building](#vocab)\n",
    "    * [7.2. Dataset Loading](#dataset_load)\n",
    "* [8. Trainer](#trainer)\n",
    "    * [8.1. Optimizer Scheduler](#optim_schedule)\n",
    "    * [8.2. Pre-train](#pretrain)\n",
    "* [9. Fine-tuning](#finetuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports <a class=\"anchor\" id=\"imports\"></a> \n",
    "-> *[Top](#top)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Utils <a class=\"anchor\" id=\"utils\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. GeLu <a class=\"anchor\" id=\"gelu\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper Section 3.4, last paragraph notice that BERT used the GELU instead of RELU\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Layer Norm <a class=\"anchor\" id=\"layer_norm\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" \n",
    "    Construct a layer norm \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Feed Forward <a class=\"anchor\" id=\"feedforward\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Attention <a class=\"anchor\" id=\"attention\"></a>\n",
    "-> *[Top](#top)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Single attention <a class=\"anchor\" id=\"single_attention\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import math\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\" \n",
    "    Computes 'Scaled Dot Product Attention' \n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(query.size(-1))\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        p_attn = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "            \n",
    "        return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Multi-head attention <a class=\"anchor\" id=\"multihead_attention\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from .single import Attention\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-headed Attention - Takes in `model size` and `number of heads`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0\n",
    "        \n",
    "        # Assuming always d_k = d_v\"\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        \n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n",
    "        self.output_layer = nn.Linear(d_model, d_model)\n",
    "        self.attention = Attention()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        # 1- Do all projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for l, x in zip(self.linear_layers, (query, key, value))\n",
    "        ]\n",
    "        # 2- Apply attention on all of the projected vectors in batch (`h` attention head)\n",
    "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        # 3- \"Concat\" all attention heads using a view and apply a final linear\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "        \n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Encoder Layer <a class=\"anchor\" id=\"encoder\"></a>\n",
    "-> *[Top](#top)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Sublayer Connection <a class=\"anchor\" id=\"sublayer\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from .layer_nor import LayerNorm\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies a residual network followed by a layer norm\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Position-wise Feedforward <a class=\"anchor\" id=\"position_feedforward\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from .gelu import GELU\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a feed-forward network layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "        self.activation = GELU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.w_2(\n",
    "            self.dropout(\n",
    "                self.activation(self.w_1(x))\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Transformer Block <a class=\"anchor\" id=\"transformer_block\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from .utils import SublayerConnection, PositionwiseFeedForward\n",
    "# from .attention import MultiHeadedAttention\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional Encoder = Transformer(self-attention)\n",
    "    \n",
    "    Transformer = Multiheaded_Attention + FeedForward with Sublayer conneciton\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden, attn_heads, feed_forward_hidden, dropout):\n",
    "        \"\"\"\n",
    "        :param hidden: size of hidden layer of transformer (or `d_model`)\n",
    "        :param attn_heads: number of attention heads in multi-headed attention layer\n",
    "        :param feed_forward_hidden: size of feed forward hidden layer (usually 4*hidden)\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=feed_forward_hidden, dropout=dropout)\n",
    "        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.input_sublayer(x, lambda _x: self.attention.forward(_x, _x, _x, mask=mask))\n",
    "        x = self.output_sublayer(x, self.feed_forward)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Embeddings <a class=\"anchor\" id=\"embeddings\"></a>\n",
    "-> *[Top](#top)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Token Embedding <a class=\"anchor\" id=\"token_embedding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, embed_size=512):\n",
    "        super().__init__(vocab_size, embed_size, padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Position Embedding <a class=\"anchor\" id=\"position_embedding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        # compute the positional encoding\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "        \n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        division = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * division)\n",
    "        pe[:, 1::2] = torch.cos(position * division)\n",
    "        \n",
    "        pe = pe.unsqueeze(0)\n",
    "        # Register buffer to add persistent state without counting it as a parameter\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Segment Embedding <a class=\"anchor\" id=\"segment_embedding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SegmentEmbedding(nn.Embedding):\n",
    "    def __init__(self, embed_size=512):\n",
    "        super().__init__(3, embed_size, padding_idx=0) # vocab size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. BERT Embedding <a class=\"anchor\" id=\"bert_embedding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from .token import TokenEmbedding\n",
    "# from .position import PositionalEmbedding\n",
    "# from .segment import SegmentEmbedding\n",
    "\n",
    "class BERTEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT embedding is consisted of three different embeddings:\n",
    "        - Token Embedding\n",
    "        - Positional Embedding\n",
    "        - Segment Embedding\n",
    "    The final embedding is the summation of all these three embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, dropout):\n",
    "        \"\"\"\n",
    "        :param vocab_size\t: size of vocabulary\n",
    "        :param embed_size\t: size of token embedding\n",
    "        :param dropout\t\t: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token = TokenEmbedding(vocab_size=vocab_size, embed_size=embed_size)\n",
    "        self.position = PositionalEmbedding(d_model=self.token.embedding_dim)\n",
    "        self.segment = SegmentEmbedding(embed_size=self.token.embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "    def forward(self, sequence, segment_label):\n",
    "        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model <a class=\"anchor\" id=\"model\"></a>\n",
    "-> *[Top](#top)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. BERT <a class=\"anchor\" id=\"bert\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# from .transformer import Transformer\n",
    "# from .embedding import BERTEmbedding\n",
    "\n",
    "class BERT(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT model: Bidirectional Encoder Representations from Transformers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden=768, n_layers=12, attn_heads=12, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: size of vocabulary\n",
    "        :param hidden: size of BERT hidden layers\n",
    "        :param n_layers: number of Transformer blocks (layers)\n",
    "        :param attn_heads: number of attention heads in multi-headed attention\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden = hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.attn_heads = attn_heads\n",
    "        self.feed_forward_hidden = hidden * 4\n",
    "        \n",
    "        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=hidden, dropout=dropout)\n",
    "        self.transformers = nn.ModuleList([\n",
    "            Transformer(\n",
    "                hidden=hidden, \n",
    "                attn_heads=attn_heads, \n",
    "                feed_forward_hidden=self.feed_forward_hidden, \n",
    "                dropout=dropout\n",
    "            ) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, segment_labels):\n",
    "        # Creating attention mask for padding tokens\n",
    "        mask = (x>0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
    "        \n",
    "        x = self.embedding(x, segment_labels)\n",
    "        \n",
    "        for transformer in self.transformers:\n",
    "            x = transformer.forward(x, mask=mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Masked Language Model <a class=\"anchor\" id=\"masked_lm\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MaskedLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    n-class classification module (n-class = vocab_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden, vocab_size):\n",
    "        \"\"\"\n",
    "        :param hidden : size of hidden layers in Transformer block\n",
    "        :param vocab_size : size of vocabulary (= n_class)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Next Sentence Prediction <a class=\"anchor\" id=\"nsp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NextSentencePrediction(nn.Module):\n",
    "    \"\"\"\n",
    "    2-class classification model: `is_next`, `is_not_next`\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden):\n",
    "        \"\"\"\n",
    "        :param hidden: BERT hidden layer size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6.4. BERT Language Model <a class=\"anchor\" id=\"bert_lm\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTLM(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Language Model (with NSP + MLM)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bert: BERT, vocab_size):\n",
    "        \"\"\"\n",
    "        :param bert : BERT model to be trained\n",
    "        :param vocab_size : vocabulary size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.next_sentence = NextSentencePrediction(self.bert.hidden)\n",
    "        self.masked_lm = MaskedLanguageModel(hidden=self.bert.hidden, vocab_size=vocab_size)\n",
    "        \n",
    "    def forward(self, x, segment_labels):\n",
    "        x = self.bert(x, segment_labels)\n",
    "        return self.next_sentence(x), self.masked_lm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Dataset <a class=\"anchor\" id=\"dataset\"></a>\n",
    "-> *[Top](#top)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Vocabulary Building <a class=\"anchor\" id=\"vocab\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "# from multiprocessing import Pool\n",
    "from pathos.multiprocessing import ProcessPool as Pool\n",
    "\n",
    "\n",
    "class TorchVocab(object):\n",
    "    \"\"\"Defines a vocabulary object that will be used to numericalize a field.\n",
    "    Attributes:\n",
    "        freqs: A collections.Counter object holding the frequencies of tokens\n",
    "            in the data used to build the Vocab.\n",
    "        stoi: A collections.defaultdict instance mapping token strings to\n",
    "            numerical identifiers.\n",
    "        itos: A list of token strings indexed by their numerical identifiers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, counter, max_size=None, min_freq=1, specials=['<pad>', '<oov>'],\n",
    "                 vectors=None, unk_init=None, vectors_cache=None):\n",
    "        \"\"\"Create a Vocab object from a collections.Counter.\n",
    "        Arguments:\n",
    "            counter: collections.Counter object holding the frequencies of\n",
    "                each value found in the data.\n",
    "            max_size: The maximum size of the vocabulary, or None for no\n",
    "                maximum. Default: None.\n",
    "            min_freq: The minimum frequency needed to include a token in the\n",
    "                vocabulary. Values less than 1 will be set to 1. Default: 1.\n",
    "            specials: The list of special tokens (e.g., padding or eos) that\n",
    "                will be prepended to the vocabulary in addition to an <unk>\n",
    "                token. Default: ['<pad>']\n",
    "            vectors: One of either the available pretrained vectors\n",
    "                or custom pretrained vectors (see Vocab.load_vectors);\n",
    "                or a list of aforementioned vectors\n",
    "            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n",
    "                to zero vectors; can be any function that takes in a Tensor and\n",
    "                returns a Tensor of the same size. Default: torch.Tensor.zero_\n",
    "            vectors_cache: directory for cached vectors. Default: '.vector_cache'\n",
    "        \"\"\"\n",
    "        self.freqs = counter\n",
    "        counter = counter.copy()\n",
    "        min_freq = max(min_freq, 1)\n",
    "\n",
    "        self.itos = list(specials)\n",
    "        # frequencies of special tokens are not counted when building vocabulary\n",
    "        # in frequency order\n",
    "        for tok in specials:\n",
    "            del counter[tok]\n",
    "\n",
    "        max_size = None if max_size is None else max_size + len(self.itos)\n",
    "\n",
    "        # sort by frequency, then alphabetically\n",
    "        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n",
    "        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "        for word, freq in words_and_frequencies:\n",
    "            if freq < min_freq or len(self.itos) == max_size:\n",
    "                break\n",
    "            self.itos.append(word)\n",
    "\n",
    "        # stoi is simply a reverse dict for itos\n",
    "        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n",
    "\n",
    "        self.vectors = None\n",
    "        if vectors is not None:\n",
    "            self.load_vectors(vectors, unk_init=unk_init, cache=vectors_cache)\n",
    "        else:\n",
    "            assert unk_init is None and vectors_cache is None\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if self.freqs != other.freqs:\n",
    "            return False\n",
    "        if self.stoi != other.stoi:\n",
    "            return False\n",
    "        if self.itos != other.itos:\n",
    "            return False\n",
    "        if self.vectors != other.vectors:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def vocab_rerank(self):\n",
    "        self.stoi = {word: i for i, word in enumerate(self.itos)}\n",
    "\n",
    "    def extend(self, v, sort=False):\n",
    "        words = sorted(v.itos) if sort else v.itos\n",
    "        for w in words:\n",
    "            if w not in self.stoi:\n",
    "                self.itos.append(w)\n",
    "                self.stoi[w] = len(self.itos) - 1\n",
    "\n",
    "\n",
    "class Vocab(TorchVocab):\n",
    "    def __init__(\n",
    "        self, counter, max_size=None, min_freq=1, \n",
    "        pad_token=\"[PAD]\",\n",
    "        unk_token=\"[UNK]\",\n",
    "        sep_token=\"[SEP]\",\n",
    "        cls_token=\"[CLS]\",\n",
    "        mask_token=\"[MASK]\",\n",
    "    ):\n",
    "        self.pad_index = 0\n",
    "        self.unk_index = 1\n",
    "        self.sep_index = 2\n",
    "        self.cls_index = 3\n",
    "        self.mask_index = 4\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        self.sep_token = sep_token\n",
    "        self.cls_token = cls_token\n",
    "        self.mask_token = mask_token\n",
    "        \n",
    "        super().__init__(counter, specials=[pad_token, unk_token, sep_token, cls_token, mask_token],\n",
    "                         max_size=max_size, min_freq=min_freq)\n",
    "\n",
    "    def to_seq(self, sentece, seq_len, with_sep=False, with_cls=False) -> list:\n",
    "        pass\n",
    "\n",
    "    def from_seq(self, seq, join=False, with_pad=False):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vocab(vocab_path: str) -> 'Vocab':\n",
    "        with open(vocab_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def save_vocab(self, vocab_path):\n",
    "        with open(vocab_path, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "\n",
    "# Building Vocab with text files\n",
    "class WordVocab(Vocab):\n",
    "    def __init__(\n",
    "        self, texts, tok_train_path, max_size=None, min_freq=1,\n",
    "        pad_token=\"[PAD]\",\n",
    "        unk_token=\"[UNK]\",\n",
    "        sep_token=\"[SEP]\",\n",
    "        cls_token=\"[CLS]\",\n",
    "        mask_token=\"[MASK]\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param texts : List of sentences for building the vocabulary\n",
    "        :param tok_train_path : Path to training texts for training the tokenizer\n",
    "        :param pad_token : Special token to be used for padding\n",
    "        :param unk_token : Special token to be used for unknown words\n",
    "        :param sep_token : Special token to be used as seperator\n",
    "        :param cls_token : Special token to be used as CLS\n",
    "        :param mask_token : Special token to be used for attention masking\n",
    "        \"\"\"\n",
    "        \n",
    "        # Creating Tokenizer for building the vocabulary\n",
    "        self.tokenizer = BertWordPieceTokenizer()\n",
    "        print(\"Training the tokenizer to build the vocabulary...\")\n",
    "        self.tokenizer.train(tok_train_path)\n",
    "        print(\"Training tokenizer finished successfully!\\n\")\n",
    "        \n",
    "        # Building the vocabulary\n",
    "        print(\"Building Vocab...\")\n",
    "        counter = Counter()\n",
    "        for line in tqdm(texts, total=len(texts)):\n",
    "            if isinstance(line, list):\n",
    "                words = line\n",
    "            else:\n",
    "                words = self.tokenizer.encode(line).tokens\n",
    "\n",
    "            for word in words:\n",
    "                counter[word] += 1\n",
    "                \n",
    "        super().__init__(\n",
    "            counter, max_size=max_size, min_freq=min_freq, \n",
    "            pad_token=pad_token,\n",
    "            unk_token=unk_token,\n",
    "            sep_token=sep_token,\n",
    "            cls_token=cls_token,\n",
    "            mask_token=mask_token\n",
    "        )\n",
    "\n",
    "    def to_seq(self, sentence, seq_len=None, with_sep=False, with_cls=False, with_len=False):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = self.tokenizer.encode(sentence).tokens\n",
    "\n",
    "        seq = [self.stoi.get(word, self.unk_index) for word in sentence]\n",
    "\n",
    "        if with_sep:\n",
    "            seq += [self.sep_index]  # this would be index 1\n",
    "        if with_cls:\n",
    "            seq = [self.cls_index] + seq\n",
    "\n",
    "        origin_seq_len = len(seq)\n",
    "\n",
    "        if seq_len is None:\n",
    "            pass\n",
    "        elif len(seq) <= seq_len:\n",
    "            seq += [self.pad_index for _ in range(seq_len - len(seq))]\n",
    "        else:\n",
    "            seq = seq[:seq_len]\n",
    "\n",
    "        return (seq, origin_seq_len) if with_len else seq\n",
    "\n",
    "    def from_seq(self, seq, join=False, with_pad=False):\n",
    "        words = [self.itos[idx]\n",
    "                 if idx < len(self.itos)\n",
    "                 else \"<%d>\" % idx\n",
    "                 for idx in seq\n",
    "                 if with_pad or idx != self.pad_index]\n",
    "\n",
    "        return (\" \".join(words)).replace(\" ##\", \"\") if join else words\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vocab(vocab_path: str) -> 'WordVocab':\n",
    "        with open(vocab_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "#     def parallel_processing(self, texts, ncores=None, message=None):\n",
    "#         # from pathos.multiprocessing import ProcessPool as Pool\n",
    "#         p = Pool(ncores)\n",
    "#         return tqdm(\n",
    "#             p.imap(self.count_each_line, texts),\n",
    "#             total=len(texts), \n",
    "#             desc=message\n",
    "#         )\n",
    "    \n",
    "#     def count_each_line(self, line):\n",
    "#         if isinstance(line, list):\n",
    "#             words = line\n",
    "#         else:\n",
    "#             words = self.tokenizer.encode(line).tokens\n",
    "            \n",
    "#         return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Dataset <a class=\"anchor\" id=\"dataset_load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, corpus_path, vocab, seq_len, encoding=\"utf-8\", corpus_lines=None, on_memory=True):\n",
    "        self.vocab = vocab\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.on_memory = on_memory\n",
    "        self.corpus_lines = corpus_lines\n",
    "        self.corpus_path = corpus_path\n",
    "        self.encoding = encoding\n",
    "\n",
    "        with open(corpus_path, \"r\", encoding=encoding) as f:\n",
    "            if self.corpus_lines is None and not on_memory:\n",
    "                for _ in tqdm(f, desc=\"Loading Dataset\", total=corpus_lines):\n",
    "                    self.corpus_lines += 1\n",
    "\n",
    "            if on_memory:\n",
    "                self.lines = [line[:-1].split(\"\\t\")\n",
    "                              for line in tqdm(f, desc=\"Loading Dataset\", total=corpus_lines)]\n",
    "                self.corpus_lines = len(self.lines)\n",
    "\n",
    "        if not on_memory:\n",
    "            self.file = open(corpus_path, \"r\", encoding=encoding)\n",
    "            self.random_file = open(corpus_path, \"r\", encoding=encoding)\n",
    "\n",
    "            for _ in range(random.randint(self.corpus_lines if self.corpus_lines < 1000 else 1000)):\n",
    "                self.random_file.__next__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_lines\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        t1, t2, is_next_label = self.random_sent(item)\n",
    "        t1_random, t1_label = self.random_word(t1)\n",
    "        t2_random, t2_label = self.random_word(t2)\n",
    "\n",
    "        # [CLS] tag = SOS tag, [SEP] tag = EOS tag\n",
    "        t1 = [self.vocab.cls_index] + t1_random + [self.vocab.sep_index]\n",
    "        t2 = t2_random + [self.vocab.sep_index]\n",
    "\n",
    "        t1_label = [self.vocab.pad_index] + t1_label + [self.vocab.pad_index]\n",
    "        t2_label = t2_label + [self.vocab.pad_index]\n",
    "\n",
    "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
    "        bert_input = (t1 + t2)[:self.seq_len]\n",
    "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
    "\n",
    "        padding = [self.vocab.pad_index for _ in range(self.seq_len - len(bert_input))]\n",
    "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
    "\n",
    "        output = {\"bert_input\": bert_input,\n",
    "                  \"bert_label\": bert_label,\n",
    "                  \"segment_label\": segment_label,\n",
    "                  \"is_next\": is_next_label}\n",
    "\n",
    "        return {key: torch.tensor(value) for key, value in output.items()}\n",
    "\n",
    "    def random_word(self, sentence):\n",
    "        tokens = sentence.split()\n",
    "        output_label = []\n",
    "\n",
    "        for i, token in enumerate(tokens):\n",
    "            prob = random.random()\n",
    "            if prob < 0.15:\n",
    "                prob /= 0.15\n",
    "\n",
    "                # 80% randomly change token to mask token\n",
    "                if prob < 0.8:\n",
    "                    tokens[i] = self.vocab.mask_index\n",
    "\n",
    "                # 10% randomly change token to random token\n",
    "                elif prob < 0.9:\n",
    "                    tokens[i] = random.randrange(len(self.vocab))\n",
    "\n",
    "                # 10% randomly change token to current token\n",
    "                else:\n",
    "                    tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index)\n",
    "\n",
    "                output_label.append(self.vocab.stoi.get(token, self.vocab.unk_index))\n",
    "\n",
    "            else:\n",
    "                tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index)\n",
    "                output_label.append(0)\n",
    "\n",
    "        return tokens, output_label\n",
    "\n",
    "    def random_sent(self, index):\n",
    "        t1, t2 = self.get_corpus_line(index)\n",
    "\n",
    "        # output_text, label(isNotNext:0, isNext:1)\n",
    "        if random.random() > 0.5:\n",
    "            return t1, t2, 1\n",
    "        else:\n",
    "            return t1, self.get_random_line(), 0\n",
    "\n",
    "    def get_corpus_line(self, item):\n",
    "        if self.on_memory:\n",
    "            if self.lines[item][1]==0 or item==0:\n",
    "                return self.lines[item][0], self.lines[item+1][0]\n",
    "            else:\n",
    "                return self.lines[item-1][0], self.lines[item][0]\n",
    "        else:\n",
    "            line_1 = self.file.__next__()\n",
    "            line_2 = self.file.__next__()\n",
    "            if line_1 is None:\n",
    "                self.file.close()\n",
    "                self.file = open(self.corpus_path, \"r\", encoding=self.encoding)\n",
    "                line_1 = self.file.__next__()\n",
    "                line_2 = self.file.__next__()\n",
    "            elif line_2 is None:\n",
    "                self.file.close()\n",
    "                self.file = open(self.corpus_path, \"r\", encoding=self.encoding)\n",
    "                line_1 = self.file.__next__()\n",
    "                line_2 = self.file.__next__()\n",
    "            line_1 = line_1[:-1].split(\"\\t\")\n",
    "            line_2 = line_2[:-1].split(\"\\t\")\n",
    "            if line_2[1]==1:\n",
    "                return line_1[0], line_2[0]\n",
    "            \n",
    "            line_3 = self.file.__next__()\n",
    "            if line_3 is None:\n",
    "                self.file.close()\n",
    "                self.file = open(self.corpus_path, \"r\", encoding=self.encoding)\n",
    "                line_1 = self.file.__next__()\n",
    "                line_2 = self.file.__next__()\n",
    "                line_1 = line_1[:-1].split(\"\\t\")\n",
    "                line_2 = line_2[:-1].split(\"\\t\")\n",
    "                return line_1[0], line_2[0]\n",
    "            return line_2[0], line_3[:-1].split(\"\\t\")[0]\n",
    "\n",
    "    def get_random_line(self):\n",
    "        if self.on_memory:\n",
    "            rand_idx = random.randrange(len(self.lines))\n",
    "            return self.lines[rand_idx][0]\n",
    "\n",
    "        line = self.file.__next__()\n",
    "        if line is None:\n",
    "            self.file.close()\n",
    "            self.file = open(self.corpus_path, \"r\", encoding=self.encoding)\n",
    "            for _ in range(random.randint(self.corpus_lines if self.corpus_lines < 1000 else 1000)):\n",
    "                self.random_file.__next__()\n",
    "            line = self.random_file.__next__()\n",
    "        return line[:-1].split(\"\\t\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "class BERTDatasetOnMemory(Dataset):\n",
    "    \n",
    "    def __init__(self, corpus_path, vocab, seq_len, encoding=\"utf-8\", corpus_lines=None, on_memory=True, device='cuda'):\n",
    "        self.vocab = vocab\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.on_memory = on_memory\n",
    "        self.corpus_lines = corpus_lines\n",
    "        self.corpus_path = corpus_path\n",
    "        self.encoding = encoding\n",
    "\n",
    "        with open(corpus_path, \"r\", encoding=encoding) as f:\n",
    "            self.lines = [\n",
    "                line[:-1].split(\"\\t\")\n",
    "                for line in tqdm(f, desc=\"Loading Dataset\", total=corpus_lines)\n",
    "            ]\n",
    "            self.corpus_len = len(self.lines)\n",
    "        self.sentences, self.isnext = self._preprocess_lines(self.lines)\n",
    "        self.device = 'cpu'\n",
    "        if torch.cuda.is_available() and device=='cuda':\n",
    "            self.device = 'cuda'\n",
    "            self.sentences = [t.cuda() for t in tqdm(self.sentences, desc=\"Moving sentences to GPU...\")]\n",
    "            self.isnext = self.isnext.cuda()\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.corpus_len\n",
    "    \n",
    "    \n",
    "    def to(self, device):\n",
    "        self.sentences = [x.to(device) for x in tqdm(self.sentences, desc=f\"Moving sentences to {device.upper()}...\")]\n",
    "        self.isnext = self.isnext.to(device)\n",
    "        self.device = device\n",
    "    \n",
    "    \n",
    "    def _preprocess_lines(self, lines):\n",
    "        train_sents = []\n",
    "        train_isnext = []\n",
    "        for line in tqdm(lines):\n",
    "            tokens = line[0].split()\n",
    "            tokens_id = [self.vocab.stoi.get(tok, self.vocab.unk_index) for tok in tokens]\n",
    "            train_sents.append(torch.tensor(tokens_id).long())\n",
    "            train_isnext.append(int(line[1]))\n",
    "        train_isnext = torch.tensor(train_isnext).long()\n",
    "        \n",
    "        return train_sents, train_isnext\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        t1, t2, is_next_label = self.random_sent(item)\n",
    "        t1_random, t1_label = self.random_word(t1)\n",
    "        t2_random, t2_label = self.random_word(t2)\n",
    "\n",
    "        # [CLS] tag = SOS tag, [SEP] tag = EOS tag\n",
    "        with torch.no_grad():\n",
    "            t1 = torch.cat([torch.tensor([self.vocab.cls_index]).to(self.device), t1_random, torch.tensor([self.vocab.sep_index]).to(self.device)])\n",
    "            t2 =  torch.cat([t2_random, torch.tensor([self.vocab.sep_index]).to(self.device)])\n",
    "\n",
    "            t1_label = torch.cat([torch.tensor([self.vocab.pad_index]).to(self.device), t1_label, torch.tensor([self.vocab.pad_index]).to(self.device)])\n",
    "            t2_label = torch.cat([t2_label, torch.tensor([self.vocab.pad_index]).to(self.device)])\n",
    "\n",
    "            segment_label = torch.tensor(([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]).to(self.device)\n",
    "            bert_input = torch.cat([t1, t2])[:self.seq_len]\n",
    "            bert_label = torch.cat([t1_label, t2_label])[:self.seq_len]\n",
    "\n",
    "            padding = torch.tensor([self.vocab.pad_index for _ in range(self.seq_len - len(bert_input))]).to(self.device)\n",
    "            bert_input = torch.cat([bert_input, padding]).detach()\n",
    "            bert_label = torch.cat([bert_label, padding]).detach()\n",
    "            segment_label = torch.cat([segment_label, padding]).detach()\n",
    "\n",
    "        return {\n",
    "            \"bert_input\": bert_input.long(),\n",
    "            \"bert_label\": bert_label,\n",
    "            \"segment_label\": segment_label,\n",
    "            \"is_next\": is_next_label\n",
    "        }\n",
    "#         return {key: torch.tensor(value) for key, value in output.items()}\n",
    "\n",
    "    \n",
    "    def random_word(self, tokens):\n",
    "        tokens = tokens.detach().clone()\n",
    "        output_label = []\n",
    "        with torch.no_grad():\n",
    "            for i, token in enumerate(tokens):\n",
    "                prob = random.random()\n",
    "                if prob < 0.15:\n",
    "                    prob /= 0.15\n",
    "\n",
    "                    # 80% randomly change token to mask token\n",
    "                    if prob < 0.8:\n",
    "                        tokens[i] = self.vocab.mask_index\n",
    "\n",
    "                    # 10% randomly change token to random token\n",
    "                    elif prob < 0.9:\n",
    "                        tokens[i] = int(random.randrange(len(self.vocab)))\n",
    "\n",
    "                    # 10% randomly change token to current token\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                    output_label.append(token)\n",
    "\n",
    "                else:\n",
    "                    # tokens[i] = token\n",
    "                    output_label.append(0)\n",
    "\n",
    "        return tokens, torch.tensor(output_label).to(self.device)\n",
    "\n",
    "    \n",
    "    def random_sent(self, index):\n",
    "        t1, t2 = self.get_corpus_line(index)\n",
    "\n",
    "        # output_text, label(isNotNext:0, isNext:1)\n",
    "        if random.random() > 0.5:\n",
    "            return t1, t2, 1\n",
    "        else:\n",
    "            return t1, self.get_random_line(), 0\n",
    "\n",
    "        \n",
    "    def get_corpus_line(self, item):\n",
    "        if self.isnext[item]==0 or item==0:\n",
    "            return self.sentences[item], self.sentences[item+1]\n",
    "        else:\n",
    "            return self.sentences[item-1], self.sentences[item]\n",
    "\n",
    "\n",
    "    def get_random_line(self):\n",
    "        rand_idx = random.randrange(len(self.lines))\n",
    "        return self.sentences[rand_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Tokenization\n",
    "-> *[Top](#top)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Wordpiece Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace_tokenize(text):\n",
    "    \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "\n",
    "class WordpieceTokenizer(object):\n",
    "    \"\"\"Runs WordPiece tokenization.\"\"\"\n",
    "\n",
    "    def __init__(self, unk_token, max_input_chars_per_word=100):\n",
    "        self.unk_token = unk_token\n",
    "        self.max_input_chars_per_word = max_input_chars_per_word\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        Tokenizes a piece of text into its word pieces. This uses a greedy longest-match-first algorithm to perform\n",
    "        tokenization using the given vocabulary.\n",
    "\n",
    "        For example, :obj:`input = \"unaffable\"` wil return as output :obj:`[\"un\", \"##aff\", \"##able\"]`.\n",
    "\n",
    "        Args:\n",
    "          text: A single token or whitespace separated tokens. This should have\n",
    "            already been passed through `BasicTokenizer`.\n",
    "\n",
    "        Returns:\n",
    "          A list of wordpiece tokens.\n",
    "        \"\"\"\n",
    "\n",
    "        output_tokens = []\n",
    "        for token in whitespace_tokenize(text):\n",
    "            chars = list(token)\n",
    "            if len(chars) > self.max_input_chars_per_word:\n",
    "                output_tokens.append(self.unk_token)\n",
    "                continue\n",
    "\n",
    "            is_bad = False\n",
    "            start = 0\n",
    "            sub_tokens = []\n",
    "            while start < len(chars):\n",
    "                end = len(chars)\n",
    "                cur_substr = None\n",
    "                while start < end:\n",
    "                    substr = \"\".join(chars[start:end])\n",
    "                    if start > 0:\n",
    "                        substr = \"##\" + substr\n",
    "                    if substr in self.vocab:\n",
    "                        cur_substr = substr\n",
    "                        break\n",
    "                    end -= 1\n",
    "                if cur_substr is None:\n",
    "                    is_bad = True\n",
    "                    break\n",
    "                sub_tokens.append(cur_substr)\n",
    "                start = end\n",
    "\n",
    "            if is_bad:\n",
    "                output_tokens.append(self.unk_token)\n",
    "            else:\n",
    "                output_tokens.extend(sub_tokens)\n",
    "        return output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTokenizer():\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=vocab, unk_token=self.vocab.unk_token)\n",
    "    \n",
    "    \n",
    "    def _tokenize(self, text):\n",
    "        return self.wordpiece_tokenizer.tokenize(text)\n",
    "    \n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self.vocab.stoi.get(token, self.vocab.unk_index) for token in tokens]\n",
    "    \n",
    "    def convert_ids_to_tokens(self, token_ids):\n",
    "        tokens = [self.vocab.itos[id] for id in token_ids]\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "    def _batch_encoding(self, ):\n",
    "        pass # TO-DO\n",
    "    \n",
    "    def _pad(self, encoding):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Trainer <a class=\"anchor\" id=\"trainer\"></a>\n",
    "-> *[Top](#top)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Optimizer Scheduler <a class=\"anchor\" id=\"optim_schedule\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''A wrapper class for optimizer '''\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Pre-train <a class=\"anchor\" id=\"pretrain\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from typing import Union\n",
    "# from ..model import BERTLM, BERT\n",
    "# from .optim_schedule import ScheduledOptim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class BERTTrainer:\n",
    "    \"\"\"\n",
    "    BERTTrainer make the pretrained BERT model with two LM training method.\n",
    "        1. Masked Language Model : 3.3.1 Task #1: Masked LM\n",
    "        2. Next Sentence prediction : 3.3.2 Task #2: Next Sentence Prediction\n",
    "    please check the details on README.md with simple example.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert: BERT, vocab_size: int,\n",
    "                 train_dataloader: DataLoader, test_dataloader: DataLoader = None,\n",
    "                 lr: float = 1e-4, betas=(0.9, 0.999), weight_decay: float = 0.01, warmup_steps=10000,\n",
    "                 with_cuda: bool = True, cuda_devices=None, log_freq: int = 10, \n",
    "                 checkpoint_path: Union[str, None] = None, bert_model_path: Union[str, None] = None):\n",
    "        \"\"\"\n",
    "        :param bert: BERT model which you want to train\n",
    "        :param vocab_size: total word vocab size\n",
    "        :param train_dataloader: train dataset data loader\n",
    "        :param test_dataloader: test dataset data loader [can be None]\n",
    "        :param lr: learning rate of optimizer\n",
    "        :param betas: Adam optimizer betas\n",
    "        :param weight_decay: Adam optimizer weight decay param\n",
    "        :param with_cuda: traning with cuda\n",
    "        :param log_freq: logging frequency of the batch iteration\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup cuda device for BERT training, argument -c, --cuda should be true\n",
    "        cuda_condition = torch.cuda.is_available() and with_cuda\n",
    "        self.device = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")\n",
    "\n",
    "        # Either initializing BERT or loading from the last checkpoint\n",
    "        # This BERT model will be saved every epoch\n",
    "        self.bert = bert\n",
    "        if bert_model_path is not None:\n",
    "            print(\"Loading from checkpoint...\")\n",
    "            self.load_bert(path=bert_model_path, type=\"entire\")\n",
    "            \n",
    "        # Initialize the BERT Language Model or load it from checkpoint_path, with BERT model\n",
    "        self.model = BERTLM(bert, vocab_size)\n",
    "        if checkpoint_path is not None:\n",
    "            self.load_from_checkpoint(path=checkpoint_path)\n",
    "        # Sending the model to the appropriate device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Distributed GPU training if CUDA can detect more than 1 GPU\n",
    "        if with_cuda and torch.cuda.device_count() > 1:\n",
    "            print(\"Using %d GPUS for BERT\" % torch.cuda.device_count())\n",
    "            self.model = nn.DataParallel(self.model, device_ids=cuda_devices)\n",
    "\n",
    "        # Setting the train and test data loader\n",
    "        self.train_data = train_dataloader\n",
    "        self.test_data = test_dataloader\n",
    "\n",
    "        # Setting the Adam optimizer with hyper-param\n",
    "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        self.optim_schedule = ScheduledOptim(self.optim, self.bert.hidden, n_warmup_steps=warmup_steps)\n",
    "\n",
    "        # Using Negative Log Likelihood Loss function for predicting the masked_token\n",
    "        self.criterion = nn.NLLLoss(ignore_index=0)\n",
    "\n",
    "        self.log_freq = log_freq\n",
    "\n",
    "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.iteration(epoch, self.train_data)\n",
    "\n",
    "    def test(self, epoch):\n",
    "        self.iteration(epoch, self.test_data, train=False)\n",
    "\n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "        \"\"\"\n",
    "        loop over the data_loader for training or testing\n",
    "        if on train status, backward operation is activated\n",
    "        and also auto save the model every peoch\n",
    "        :param epoch: current epoch index\n",
    "        :param data_loader: torch.utils.data.DataLoader for iteration\n",
    "        :param train: boolean value of is train or test\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if train:\n",
    "            str_code = \"train\"\n",
    "            self.model.train()\n",
    "        else:\n",
    "            str_code = \"test\"\n",
    "            self.model.eval()\n",
    "\n",
    "        # Setting the tqdm progress bar\n",
    "        data_iter = tqdm(enumerate(data_loader),\n",
    "                         desc=\"EP_%s:%d\" % (str_code, epoch),\n",
    "                         total=len(data_loader),\n",
    "                         bar_format=\"{l_bar}{r_bar}\")\n",
    "\n",
    "        avg_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_element = 0\n",
    "        \n",
    "        for i, data in data_iter:\n",
    "            # 0. batch_data will be sent into the device(GPU or cpu)\n",
    "            data = {key: value.to(self.device) for key, value in data.items()}\n",
    "\n",
    "            # 1. forward the next_sentence_prediction and masked_lm model\n",
    "            next_sent_output, mask_lm_output = self.model.forward(data[\"bert_input\"], data[\"segment_label\"])\n",
    "\n",
    "            # 2-1. NLL(negative log likelihood) loss of is_next classification result\n",
    "            next_loss = self.criterion(next_sent_output, data[\"is_next\"])\n",
    "\n",
    "            # 2-2. NLLLoss of predicting masked token word\n",
    "            mask_loss = self.criterion(mask_lm_output.transpose(1, 2), data[\"bert_label\"])\n",
    "\n",
    "            # 2-3. Adding next_loss and mask_loss : 3.4 Pre-training Procedure\n",
    "            loss = next_loss + mask_loss\n",
    "\n",
    "            # 3. backward and optimization only in train\n",
    "            if train:\n",
    "                self.optim_schedule.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim_schedule.step_and_update_lr()\n",
    "\n",
    "            # next sentence prediction accuracy\n",
    "            correct = next_sent_output.argmax(dim=-1).eq(data[\"is_next\"]).sum().item()\n",
    "            avg_loss += loss.item()\n",
    "            total_correct += correct\n",
    "            total_element += data[\"is_next\"].nelement()\n",
    "\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch,\n",
    "                \"iter\": i,\n",
    "                \"avg_loss\": avg_loss / (i + 1),\n",
    "                \"avg_acc\": total_correct / total_element * 100,\n",
    "                \"loss\": loss.item()\n",
    "            }\n",
    "            if i % self.log_freq == 0:\n",
    "                logging.info(json.dumps(post_fix))\n",
    "            \n",
    "            if i % (2*self.log_freq) == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "\n",
    "        print(\"EP%d_%s, avg_loss=\" % (epoch, str_code), avg_loss / len(data_iter), \"total_acc=\",\n",
    "              total_correct * 100.0 / total_element)\n",
    "        final_metrics = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train\": train,\n",
    "            \"avg_loss\": avg_loss / len(data_iter),\n",
    "            \"total_acc\": total_correct * 100.0 / total_element\n",
    "        }\n",
    "        with open(\"./models/logging/bert_02_final.txt\", \"a\", encoding=\"utf-8\") as file:\n",
    "            file.write(json.dumps(final_metrics) + \"\\n\")\n",
    "\n",
    "    def save(self, epoch, file_path=\"output/bert_trained.model\"):\n",
    "        \"\"\"\n",
    "        Saving the current BERT model on file_path\n",
    "        :param epoch: current epoch number\n",
    "        :param file_path: model output path which gonna be file_path+\"ep%d\" % epoch\n",
    "        :return: final_output_path\n",
    "        \"\"\"\n",
    "        output_path = file_path + \".{}.ep{:02d}.pt\" #% epoch\n",
    "        # Saving Entire BERT model\n",
    "        torch.save(self.bert.cpu(), output_path.format(\"bert.model\", epoch))\n",
    "        # Saving only BERT state_dict\n",
    "        torch.save(self.bert.cpu().state_dict(), output_path.format(\"bert.statedict\", epoch))\n",
    "        # Saving BERT LM state_dict\n",
    "        torch.save(self.model.cpu().state_dict(), output_path.format(\"bertlm.statedict\", epoch))\n",
    "        \n",
    "        self.bert.to(self.device)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    "    \n",
    "    def load_bert(self, path, type=\"entire\"):\n",
    "        if type==\"entire\":\n",
    "            # Loading entire model\n",
    "            self.bert = torch.load(path)\n",
    "        elif type==\"state_dict\":\n",
    "            self.bert.load_state_dict(torch.load(path))\n",
    "        else:\n",
    "            raise TypeError('Parameter `type` can either be \"entire\" or \"state_dict\"')\n",
    "            \n",
    "    def load_from_checkpoint(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Pre-training <a class=\"anchor\" id=\"finetuning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Building and Training Tokenizer and Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,186\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senj no Valkyria 3 : [UNK] Chronicles ( Japan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The game began development in 2010 , carrying ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_next\n",
       "0  Senj no Valkyria 3 : [UNK] Chronicles ( Japan...        0\n",
       "1  The game began development in 2010 , carrying ...        1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    \"./wikitext-2/wikitext2_bert_train.csv\", \n",
    "    sep=\"\\t\", \n",
    "    header=None, \n",
    "    names=['text', 'is_next']\n",
    ")\n",
    "print(\"{:,}\".format(train_df.shape[0]))\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write for Tokenizer Training\n",
    "# tokenizer_train_path = \"./wikitext-2/wikitext2_bert_for_tokenizer.txt\"\n",
    "# with open(tokenizer_train_path, \"w\", encoding=\"utf-8\")  as file:\n",
    "#     for line in train_df.text.tolist():\n",
    "#         file.write(line +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary = WordVocab(texts=train_df.text, tok_train_path=tokenizer_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2f8f576eac91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vocabulary' is not defined"
     ]
    }
   ],
   "source": [
    "vocabulary.from_seq(vocabulary.to_seq(train_df['text'][0], seq_len=155), join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary.save_vocab(\"./wikitext-2/vocabulary.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_for_bert(sents):\n",
    "    print(\"Starting Batch Tokenization...\")\n",
    "    tokenized_sents = vocabulary.tokenizer.encode_batch(sents)\n",
    "    return [\n",
    "        \" \".join(x.tokens) \n",
    "        for x in tqdm(tokenized_sents, total=len(tokenized_sents), desc=\"Merging tokens...\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Tokenized Training Set BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "train_df['text'] = pd.Series(tokenize_for_bert(train_df.text))\n",
    "print(\"Time elapsed {:.2f}\".format(time.perf_counter()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"./wikitext-2/wikitext2_bert_train_tokenized.csv\", sep=\"\\t\", index=False, header=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Tokenized Test set for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03608439182435161"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optim_schedule.init_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016136301107651203"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optim.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Homarus gammarus , known as the European lobst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homarus gammarus is a large [UNK] , with a bod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_next\n",
       "0  Homarus gammarus , known as the European lobst...        0\n",
       "1  Homarus gammarus is a large [UNK] , with a bod...        1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "valid_df = pd.read_csv(\n",
    "    \"./wikitext-2/wikitext2_bert_valid.csv\", \n",
    "    sep=\"\\t\", \n",
    "    header=None, \n",
    "    names=['text', 'is_next']\n",
    ")\n",
    "print(\"{:,}\".format(valid_df.shape[0]))\n",
    "valid_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Batch Tokenization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfe5812e7b444509d443b8c0133b3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Merging tokens...', max=1726.0, style=ProgressStyle(descr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time elapsed 0.07\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "valid_df['text'] = pd.Series(tokenize_for_bert(valid_df.text))\n",
    "print(\"Time elapsed {:.2f}\".format(time.perf_counter()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_df.to_csv(\"./wikitext-2/wikitext2_bert_valid_tokenized.csv\", \n",
    "#                 sep=\"\\t\", index=False, header=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Pre-training BERT Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='./models/logging/bert_02_logs.jsonl', \n",
    "    filemode='a', \n",
    "    encoding='utf-8', \n",
    "    level=logging.INFO,\n",
    "    format='{\"name\": \"%(name)s\", \"levelname\": \"%(levelname)s\", \"message\":%(message)s}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"./models/logging/bert_01_logs.jsonl\", \"r\") as file:\n",
    "#     json_list = [json.loads(line) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line in json_list:\n",
    "#     logging.info(json.dumps(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e387bd82dde4ac397848d7615b9ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Dataset', max=16186.0, style=ProgressStyle(descri"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4826ba733a9a403eb0bdb46899355ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Loading Dataset', layout=Layout(width='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_path = \"./wikitext-2/vocabulary.pkl\"\n",
    "train_ds_path = \"./wikitext-2/wikitext2_bert_train_tokenized.csv\"\n",
    "valid_ds_path = \"./wikitext-2/wikitext2_bert_valid_tokenized.csv\"\n",
    "seq_len = 384\n",
    "corpus_lines = int(train_df.shape[0])\n",
    "on_memory = True\n",
    "batch_size = 16\n",
    "num_workers = 22\n",
    "attn_heads = 12\n",
    "layers = 8\n",
    "hidden = 768\n",
    "lr = 5e-5\n",
    "adam_beta1, adam_beta2 = 0.9, 0.999\n",
    "adam_weight_decay = 0.01\n",
    "with_cuda = True\n",
    "cuda_devices = 1\n",
    "log_freq = 200\n",
    "epochs = 100\n",
    "output_path = \"./models/bert_02_small\"\n",
    "test_dataset = None\n",
    "\n",
    "vocab = WordVocab.load_vocab(vocab_path)\n",
    "train_dataset = BERTDataset(train_ds_path, vocab, seq_len=seq_len,\n",
    "                            corpus_lines=corpus_lines, on_memory=on_memory)\n",
    "# print(\"Loading Test Dataset\", args.test_dataset)\n",
    "test_dataset = BERTDataset(valid_ds_path, vocab, seq_len=seq_len, on_memory=on_memory) \\\n",
    "    if valid_ds_path is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataloader\n",
      "Building BERT model\n",
      "Creating BERT Trainer\n",
      "Total Parameters: 94793678\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Dataloader\")\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=22)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=22) \\\n",
    "    if test_dataset is not None else None\n",
    "\n",
    "print(\"Building BERT model\")\n",
    "bert = BERT(len(vocab), hidden=hidden, n_layers=layers, attn_heads=attn_heads)\n",
    "\n",
    "print(\"Creating BERT Trainer\")\n",
    "trainer = BERTTrainer(bert, len(vocab), train_dataloader=train_data_loader, test_dataloader=test_data_loader,\n",
    "                      lr=lr, betas=(adam_beta1, adam_beta2), weight_decay=adam_weight_decay,\n",
    "                      with_cuda=with_cuda, cuda_devices=cuda_devices, log_freq=log_freq, \n",
    "#                       checkpoint_path=\"./models/bert_01.bertlm.statedict.ep02.pt\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1849d0aa8f414b60b02bb9701e960910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:0', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 0, 'avg_loss': 12.726310729980469, 'avg_acc': 68.75, 'loss': 12.726310729980469}\n",
      "{'epoch': 0, 'iter': 400, 'avg_loss': 9.461090229395916, 'avg_acc': 49.3142144638404, 'loss': 7.554988384246826}\n",
      "{'epoch': 0, 'iter': 800, 'avg_loss': 8.468101362759404, 'avg_acc': 49.53183520599251, 'loss': 7.329710483551025}\n",
      "\n",
      "EP0_train, avg_loss= 8.195631435737308 total_acc= 49.57370567156802\n",
      "EP:0 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2601d0dd1be5426e9a5fd0a77ae0858e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:0', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 0, 'avg_loss': 7.475540637969971, 'avg_acc': 37.5, 'loss': 7.475540637969971}\n",
      "\n",
      "EP0_test, avg_loss= 7.322490140243813 total_acc= 51.33256083429896\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54605ffb88244778169e3bd81e0986d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:1', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'iter': 0, 'avg_loss': 6.9870991706848145, 'avg_acc': 43.75, 'loss': 6.9870991706848145}\n",
      "{'epoch': 1, 'iter': 400, 'avg_loss': 7.066003132342103, 'avg_acc': 50.88840399002493, 'loss': 7.271169662475586}\n",
      "{'epoch': 1, 'iter': 800, 'avg_loss': 7.037893726286965, 'avg_acc': 50.749063670411985, 'loss': 6.891916275024414}\n",
      "\n",
      "EP1_train, avg_loss= 7.021967653229303 total_acc= 50.772272334115904\n",
      "EP:1 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295a69f3bc4b4dd18c91b868f5a1a72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:1', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'iter': 0, 'avg_loss': 7.128962516784668, 'avg_acc': 62.5, 'loss': 7.128962516784668}\n",
      "\n",
      "EP1_test, avg_loss= 7.249704639116923 total_acc= 49.826187717265356\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674e3460af2049a2a9721dbc395514f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:2', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2, 'iter': 0, 'avg_loss': 6.996368408203125, 'avg_acc': 62.5, 'loss': 6.996368408203125}\n",
      "{'epoch': 2, 'iter': 400, 'avg_loss': 6.941265638926975, 'avg_acc': 49.00249376558604, 'loss': 6.579565525054932}\n",
      "{'epoch': 2, 'iter': 800, 'avg_loss': 6.918057811394166, 'avg_acc': 49.61766541822721, 'loss': 6.605149745941162}\n",
      "\n",
      "EP2_train, avg_loss= 6.912844444452067 total_acc= 49.59841838625973\n",
      "EP:2 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de56ea3b8283404bbb7175db8bb445a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:2', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2, 'iter': 0, 'avg_loss': 7.267695903778076, 'avg_acc': 68.75, 'loss': 7.267695903778076}\n",
      "\n",
      "EP2_test, avg_loss= 7.090606265597874 total_acc= 50.115874855156434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8db452a0694c14bd69803ef6bf3c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:3', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 3, 'iter': 0, 'avg_loss': 7.030896186828613, 'avg_acc': 50.0, 'loss': 7.030896186828613}\n",
      "{'epoch': 3, 'iter': 400, 'avg_loss': 6.8442567078549965, 'avg_acc': 49.20511221945137, 'loss': 6.7324604988098145}\n",
      "{'epoch': 3, 'iter': 800, 'avg_loss': 6.829695631353447, 'avg_acc': 49.38358302122347, 'loss': 6.476406574249268}\n",
      "\n",
      "EP3_train, avg_loss= 6.826710196351817 total_acc= 49.20301495119239\n",
      "EP:3 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9ccfaae56e45f4bd41ff434ed433ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:3', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 3, 'iter': 0, 'avg_loss': 6.966486930847168, 'avg_acc': 37.5, 'loss': 6.966486930847168}\n",
      "\n",
      "EP3_test, avg_loss= 6.957973855513114 total_acc= 52.6071842410197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4a3d33752746a8bd59d720d275cdf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:4', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'iter': 0, 'avg_loss': 6.971465110778809, 'avg_acc': 43.75, 'loss': 6.971465110778809}\n",
      "{'epoch': 4, 'iter': 400, 'avg_loss': 6.8125913589078, 'avg_acc': 49.76620947630923, 'loss': 6.471914768218994}\n",
      "{'epoch': 4, 'iter': 800, 'avg_loss': 6.814100888189156, 'avg_acc': 49.89076154806492, 'loss': 6.547294616699219}\n",
      "\n",
      "EP4_train, avg_loss= 6.818777200732778 total_acc= 49.54899295687631\n",
      "EP:4 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3104286bd6642898f9f6f608e2fab78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:4', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'iter': 0, 'avg_loss': 7.017176151275635, 'avg_acc': 50.0, 'loss': 7.017176151275635}\n",
      "\n",
      "EP4_test, avg_loss= 6.862703685407285 total_acc= 47.740440324449594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9c793ffedd4936883b6b9cc672ca4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:5', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 5, 'iter': 0, 'avg_loss': 6.804322719573975, 'avg_acc': 37.5, 'loss': 6.804322719573975}\n",
      "{'epoch': 5, 'iter': 400, 'avg_loss': 6.818057552537419, 'avg_acc': 50.592269326683294, 'loss': 6.810786724090576}\n",
      "{'epoch': 5, 'iter': 800, 'avg_loss': 6.816928582542696, 'avg_acc': 50.37453183520599, 'loss': 6.6378021240234375}\n",
      "\n",
      "EP5_train, avg_loss= 6.817512456607441 total_acc= 50.46336340046954\n",
      "EP:5 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188c6418e92c4a80b8b868c50d5f69db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:5', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 5, 'iter': 0, 'avg_loss': 6.873398780822754, 'avg_acc': 31.25, 'loss': 6.873398780822754}\n",
      "\n",
      "EP5_test, avg_loss= 6.78973592210699 total_acc= 49.94206257242178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99852b10733040a391e729e6017f91f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:6', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 6, 'iter': 0, 'avg_loss': 7.037576675415039, 'avg_acc': 31.25, 'loss': 7.037576675415039}\n",
      "{'epoch': 6, 'iter': 400, 'avg_loss': 6.8287684875830745, 'avg_acc': 50.46758104738155, 'loss': 6.65717077255249}\n",
      "{'epoch': 6, 'iter': 800, 'avg_loss': 6.830229825294866, 'avg_acc': 49.664481897627965, 'loss': 6.83324670791626}\n",
      "\n",
      "EP6_train, avg_loss= 6.834485354630844 total_acc= 49.81465463981218\n",
      "EP:6 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1098a6f8242244eca4f161d6935ad4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:6', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 6, 'iter': 0, 'avg_loss': 6.587947368621826, 'avg_acc': 62.5, 'loss': 6.587947368621826}\n",
      "\n",
      "EP6_test, avg_loss= 6.664273875731009 total_acc= 50.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bac1bd54954c6cbf32880160c27ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:7', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 7, 'iter': 0, 'avg_loss': 6.9102654457092285, 'avg_acc': 56.25, 'loss': 6.9102654457092285}\n",
      "{'epoch': 7, 'iter': 400, 'avg_loss': 6.863005636933439, 'avg_acc': 50.670199501246884, 'loss': 6.619730472564697}\n",
      "{'epoch': 7, 'iter': 800, 'avg_loss': 6.86993715617243, 'avg_acc': 50.530586766541816, 'loss': 6.759713172912598}\n",
      "\n",
      "EP7_train, avg_loss= 6.875325883801276 total_acc= 50.370690720375634\n",
      "EP:7 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a5fd8276c3474fbf7d7338e897d37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:7', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 7, 'iter': 0, 'avg_loss': 6.536777973175049, 'avg_acc': 56.25, 'loss': 6.536777973175049}\n",
      "\n",
      "EP7_test, avg_loss= 6.643185615539551 total_acc= 48.43568945538818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d2867825b84d7fbe6e344b99b9deca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:8', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 8, 'iter': 0, 'avg_loss': 6.864974498748779, 'avg_acc': 50.0, 'loss': 6.864974498748779}\n",
      "{'epoch': 8, 'iter': 400, 'avg_loss': 6.886917651740095, 'avg_acc': 49.37655860349127, 'loss': 6.765318393707275}\n",
      "{'epoch': 8, 'iter': 800, 'avg_loss': 6.89675923739182, 'avg_acc': 49.56304619225968, 'loss': 6.883667469024658}\n",
      "\n",
      "EP8_train, avg_loss= 6.899116648515694 total_acc= 49.7961201037934\n",
      "EP:8 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65f65f5f2414d8ea2e737aef5574969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:8', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 8, 'iter': 0, 'avg_loss': 6.619323253631592, 'avg_acc': 50.0, 'loss': 6.619323253631592}\n",
      "\n",
      "EP8_test, avg_loss= 6.720549481886405 total_acc= 49.76825028968714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d824ece8853346fbbd6085c79afd85a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:9', max=1012.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 9, 'iter': 0, 'avg_loss': 7.0588274002075195, 'avg_acc': 62.5, 'loss': 7.0588274002075195}\n",
      "{'epoch': 9, 'iter': 400, 'avg_loss': 6.9114387564528315, 'avg_acc': 49.37655860349127, 'loss': 6.919217586517334}\n",
      "{'epoch': 9, 'iter': 800, 'avg_loss': 6.92008132613107, 'avg_acc': 49.92977528089887, 'loss': 6.873764514923096}\n",
      "\n",
      "EP9_train, avg_loss= 6.925940754856517 total_acc= 50.006178178672926\n",
      "EP:9 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa625e47ccb4dc0a057c244fa2bd925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:9', max=108.0, style=ProgressStyle(description_wi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 9, 'iter': 0, 'avg_loss': 6.743729591369629, 'avg_acc': 56.25, 'loss': 6.743729591369629}\n",
      "\n",
      "EP9_test, avg_loss= 6.754164567700139 total_acc= 49.826187717265356\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579b3108b9bf4751a670b1fe67204f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:10', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 10, 'iter': 0, 'avg_loss': 6.961677551269531, 'avg_acc': 81.25, 'loss': 6.961677551269531}\n",
      "{'epoch': 10, 'iter': 400, 'avg_loss': 6.951360955797229, 'avg_acc': 50.29613466334164, 'loss': 6.933630466461182}\n",
      "{'epoch': 10, 'iter': 800, 'avg_loss': 6.961704770872804, 'avg_acc': 49.953183520599254, 'loss': 6.908087730407715}\n",
      "\n",
      "EP10_train, avg_loss= 6.961410544606537 total_acc= 50.14827628815026\n",
      "EP:10 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6e87fe8ef449a6b317fdb995996e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:10', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 10, 'iter': 0, 'avg_loss': 6.80170202255249, 'avg_acc': 56.25, 'loss': 6.80170202255249}\n",
      "\n",
      "EP10_test, avg_loss= 6.786875345088817 total_acc= 49.2468134414832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69827e27e544cc3998520747887da4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:11', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 11, 'iter': 0, 'avg_loss': 6.930217266082764, 'avg_acc': 31.25, 'loss': 6.930217266082764}\n",
      "{'epoch': 11, 'iter': 400, 'avg_loss': 6.965336998204638, 'avg_acc': 50.202618453865334, 'loss': 6.820492267608643}\n",
      "{'epoch': 11, 'iter': 800, 'avg_loss': 6.966699540689494, 'avg_acc': 50.156054931335824, 'loss': 6.648755073547363}\n",
      "\n",
      "EP11_train, avg_loss= 6.966905842185492 total_acc= 50.38922525639442\n",
      "EP:11 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec91d5107e44c1b8c7b689fe92bb289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:11', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 11, 'iter': 0, 'avg_loss': 6.835878372192383, 'avg_acc': 43.75, 'loss': 6.835878372192383}\n",
      "\n",
      "EP11_test, avg_loss= 6.903483615981208 total_acc= 51.1008111239861\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d756a8c7da742568e97741cb6cce2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:12', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 12, 'iter': 0, 'avg_loss': 6.972602844238281, 'avg_acc': 31.25, 'loss': 6.972602844238281}\n",
      "{'epoch': 12, 'iter': 400, 'avg_loss': 6.973631367719085, 'avg_acc': 51.15336658354115, 'loss': 6.887393951416016}\n",
      "{'epoch': 12, 'iter': 800, 'avg_loss': 6.976515156797107, 'avg_acc': 50.452559300873915, 'loss': 6.895035266876221}\n",
      "\n",
      "EP12_train, avg_loss= 6.98050882034151 total_acc= 50.25330532559001\n",
      "EP:12 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3c95375ec04ceb951a92fc7fb344f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:12', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 12, 'iter': 0, 'avg_loss': 6.803015232086182, 'avg_acc': 43.75, 'loss': 6.803015232086182}\n",
      "\n",
      "EP12_test, avg_loss= 6.909099088774787 total_acc= 50.7531865585168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3f12764ae74332a1a6b093aa272e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:13', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 13, 'iter': 0, 'avg_loss': 7.015468597412109, 'avg_acc': 75.0, 'loss': 7.015468597412109}\n",
      "{'epoch': 13, 'iter': 400, 'avg_loss': 6.983031288346745, 'avg_acc': 50.07793017456359, 'loss': 6.838181972503662}\n",
      "{'epoch': 13, 'iter': 800, 'avg_loss': 6.987356431177642, 'avg_acc': 49.92977528089887, 'loss': 6.840852737426758}\n",
      "\n",
      "EP13_train, avg_loss= 6.98765522170915 total_acc= 49.82701099715804\n",
      "EP:13 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7c87f31a6c4de2b98795cbae428e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:13', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 13, 'iter': 0, 'avg_loss': 6.906279563903809, 'avg_acc': 56.25, 'loss': 6.906279563903809}\n",
      "\n",
      "EP13_test, avg_loss= 6.878957593882525 total_acc= 49.304750869061415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6fd776b5764368a8264824459f4057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:14', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 14, 'iter': 0, 'avg_loss': 6.993631362915039, 'avg_acc': 50.0, 'loss': 6.993631362915039}\n",
      "{'epoch': 14, 'iter': 400, 'avg_loss': 6.974552749101063, 'avg_acc': 50.23379052369077, 'loss': 7.028587818145752}\n",
      "{'epoch': 14, 'iter': 800, 'avg_loss': 6.980695825093397, 'avg_acc': 49.9063670411985, 'loss': 6.806819438934326}\n",
      "\n",
      "EP14_train, avg_loss= 6.981312216506174 total_acc= 50.06178178672927\n",
      "EP:14 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657e045c0b884606ad09c22a5771a041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:14', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 14, 'iter': 0, 'avg_loss': 7.003608226776123, 'avg_acc': 62.5, 'loss': 7.003608226776123}\n",
      "\n",
      "EP14_test, avg_loss= 6.964668896463182 total_acc= 51.04287369640788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840e2b476aef4433ae1db7c896778150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:15', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 15, 'iter': 0, 'avg_loss': 7.029394626617432, 'avg_acc': 56.25, 'loss': 7.029394626617432}\n",
      "{'epoch': 15, 'iter': 400, 'avg_loss': 6.9855707327921195, 'avg_acc': 48.70635910224439, 'loss': 6.793706893920898}\n",
      "{'epoch': 15, 'iter': 800, 'avg_loss': 6.984862353768985, 'avg_acc': 49.13389513108614, 'loss': 6.799369812011719}\n",
      "\n",
      "EP15_train, avg_loss= 6.982995202890026 total_acc= 49.450142098109474\n",
      "EP:15 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b112bebde3547ac85ad1178de03789f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:15', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 15, 'iter': 0, 'avg_loss': 6.798563003540039, 'avg_acc': 56.25, 'loss': 6.798563003540039}\n",
      "\n",
      "EP15_test, avg_loss= 6.934547110840127 total_acc= 49.42062572421784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abdf31a01ee454ca8bc10abe97d98d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:16', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 16, 'iter': 0, 'avg_loss': 7.081331729888916, 'avg_acc': 50.0, 'loss': 7.081331729888916}\n",
      "{'epoch': 16, 'iter': 400, 'avg_loss': 6.973139608292805, 'avg_acc': 49.220698254364095, 'loss': 6.797079086303711}\n",
      "{'epoch': 16, 'iter': 800, 'avg_loss': 6.976266743092054, 'avg_acc': 49.664481897627965, 'loss': 6.764641284942627}\n",
      "\n",
      "EP16_train, avg_loss= 6.976950179446828 total_acc= 49.944396391943656\n",
      "EP:16 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42b8f9d49924fe4a76b533fb414386a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:16', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 16, 'iter': 0, 'avg_loss': 7.116652011871338, 'avg_acc': 50.0, 'loss': 7.116652011871338}\n",
      "\n",
      "EP16_test, avg_loss= 6.964293625619677 total_acc= 49.594438006952494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780a366340fa4ea3976624cc2be91fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:17', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 17, 'iter': 0, 'avg_loss': 7.008421897888184, 'avg_acc': 50.0, 'loss': 7.008421897888184}\n",
      "{'epoch': 17, 'iter': 400, 'avg_loss': 6.9819355700675985, 'avg_acc': 50.60785536159601, 'loss': 7.084016799926758}\n",
      "{'epoch': 17, 'iter': 800, 'avg_loss': 6.9783491350143, 'avg_acc': 49.953183520599254, 'loss': 6.905210971832275}\n",
      "\n",
      "EP17_train, avg_loss= 6.981885932650962 total_acc= 49.80847646113926\n",
      "EP:17 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938f46519a184ee08b83a221bc869e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:17', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 17, 'iter': 0, 'avg_loss': 6.767923831939697, 'avg_acc': 56.25, 'loss': 6.767923831939697}\n",
      "\n",
      "EP17_test, avg_loss= 6.914689050780402 total_acc= 48.8991888760139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0445b5ac92594e79b1407016c7a9cd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:18', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 18, 'iter': 0, 'avg_loss': 7.027040481567383, 'avg_acc': 25.0, 'loss': 7.027040481567383}\n",
      "{'epoch': 18, 'iter': 400, 'avg_loss': 6.9795541537372845, 'avg_acc': 50.483167082294266, 'loss': 6.848891735076904}\n",
      "{'epoch': 18, 'iter': 800, 'avg_loss': 6.978407734193457, 'avg_acc': 49.9063670411985, 'loss': 6.923051834106445}\n",
      "\n",
      "EP18_train, avg_loss= 6.979468770649122 total_acc= 50.1359199308044\n",
      "EP:18 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058580f0befb433296debb4549e3cde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:18', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 18, 'iter': 0, 'avg_loss': 7.02012300491333, 'avg_acc': 62.5, 'loss': 7.02012300491333}\n",
      "\n",
      "EP18_test, avg_loss= 7.052835649914211 total_acc= 50.695249130938585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5d5545489040dc847d06230763a15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:19', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 19, 'iter': 0, 'avg_loss': 7.082269191741943, 'avg_acc': 31.25, 'loss': 7.082269191741943}\n",
      "{'epoch': 19, 'iter': 400, 'avg_loss': 6.977348849660441, 'avg_acc': 49.76620947630923, 'loss': 7.131877899169922}\n",
      "{'epoch': 19, 'iter': 800, 'avg_loss': 6.974695294388522, 'avg_acc': 49.2665418227216, 'loss': 6.760385036468506}\n",
      "\n",
      "EP19_train, avg_loss= 6.977591747822969 total_acc= 49.51192388483875\n",
      "EP:19 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54f2d17f21d4f29af2a2ec77c322b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:19', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 19, 'iter': 0, 'avg_loss': 6.8403425216674805, 'avg_acc': 50.0, 'loss': 6.8403425216674805}\n",
      "\n",
      "EP19_test, avg_loss= 6.994916081428528 total_acc= 48.95712630359212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed42eada8c7f4c179a73ca50a0b74f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:20', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 20, 'iter': 0, 'avg_loss': 6.964524269104004, 'avg_acc': 56.25, 'loss': 6.964524269104004}\n",
      "{'epoch': 20, 'iter': 400, 'avg_loss': 6.98338708021397, 'avg_acc': 50.280548628428924, 'loss': 6.980965614318848}\n",
      "{'epoch': 20, 'iter': 800, 'avg_loss': 6.9771843301818315, 'avg_acc': 49.52403245942571, 'loss': 6.751867771148682}\n",
      "\n",
      "EP20_train, avg_loss= 6.97889167894959 total_acc= 49.83318917583097\n",
      "EP:20 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ef4a6c150e43d9a31544ebe9c7b3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:20', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 20, 'iter': 0, 'avg_loss': 6.798193454742432, 'avg_acc': 37.5, 'loss': 6.798193454742432}\n",
      "\n",
      "EP20_test, avg_loss= 6.961878794210929 total_acc= 50.28968713789108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae97d09677464181bc5b4def441e7ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:21', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 21, 'iter': 0, 'avg_loss': 6.955350399017334, 'avg_acc': 50.0, 'loss': 6.955350399017334}\n",
      "{'epoch': 21, 'iter': 400, 'avg_loss': 6.968962387551096, 'avg_acc': 49.61034912718205, 'loss': 6.989436149597168}\n",
      "{'epoch': 21, 'iter': 800, 'avg_loss': 6.971221241016364, 'avg_acc': 49.82833957553059, 'loss': 6.778234004974365}\n",
      "\n",
      "EP21_train, avg_loss= 6.9760942850188306 total_acc= 50.055603608056344\n",
      "EP:21 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa6c076ccbd4b11a22701cbf555e455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:21', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 21, 'iter': 0, 'avg_loss': 6.893987655639648, 'avg_acc': 43.75, 'loss': 6.893987655639648}\n",
      "\n",
      "EP21_test, avg_loss= 6.964837635004962 total_acc= 48.493626882966396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94981a9788864815a77f607a5cc318cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:22', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 22, 'iter': 0, 'avg_loss': 7.006428241729736, 'avg_acc': 56.25, 'loss': 7.006428241729736}\n",
      "{'epoch': 22, 'iter': 400, 'avg_loss': 6.984012960495794, 'avg_acc': 49.594763092269325, 'loss': 6.831071376800537}\n",
      "{'epoch': 22, 'iter': 800, 'avg_loss': 6.976864215288865, 'avg_acc': 49.726903870162296, 'loss': 6.816226005554199}\n",
      "\n",
      "EP22_train, avg_loss= 6.980115137552556 total_acc= 49.85172371184974\n",
      "EP:22 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5219c902a44727b86ab317c7456760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:22', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 22, 'iter': 0, 'avg_loss': 6.98036527633667, 'avg_acc': 43.75, 'loss': 6.98036527633667}\n",
      "\n",
      "EP22_test, avg_loss= 7.003145690317507 total_acc= 51.44843568945539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17e0893ad9c4120896e910e939ef1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:23', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 23, 'iter': 0, 'avg_loss': 7.032945156097412, 'avg_acc': 31.25, 'loss': 7.032945156097412}\n",
      "{'epoch': 23, 'iter': 400, 'avg_loss': 6.979116059300906, 'avg_acc': 50.18703241895261, 'loss': 7.265974998474121}\n",
      "{'epoch': 23, 'iter': 800, 'avg_loss': 6.979059526536348, 'avg_acc': 50.24188514357054, 'loss': 6.864888668060303}\n",
      "\n",
      "EP23_train, avg_loss= 6.9775732213800605 total_acc= 49.83318917583097\n",
      "EP:23 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51dae6026fb43a0829f9243d4263124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:23', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 23, 'iter': 0, 'avg_loss': 7.230944633483887, 'avg_acc': 18.75, 'loss': 7.230944633483887}\n",
      "\n",
      "EP23_test, avg_loss= 7.017015435077526 total_acc= 50.347624565469296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf7f34cf1d948a0b258a786c6f95b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:24', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 24, 'iter': 0, 'avg_loss': 7.031558990478516, 'avg_acc': 31.25, 'loss': 7.031558990478516}\n",
      "{'epoch': 24, 'iter': 400, 'avg_loss': 6.988874026367492, 'avg_acc': 49.6571072319202, 'loss': 6.990179061889648}\n",
      "{'epoch': 24, 'iter': 800, 'avg_loss': 6.979450431209378, 'avg_acc': 49.414794007490634, 'loss': 7.203375816345215}\n",
      "\n",
      "EP24_train, avg_loss= 6.978325998359047 total_acc= 49.604596564932656\n",
      "EP:24 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343322adc28446458b005e1e08777643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:24', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 24, 'iter': 0, 'avg_loss': 6.994500637054443, 'avg_acc': 50.0, 'loss': 6.994500637054443}\n",
      "\n",
      "EP24_test, avg_loss= 6.996597947897734 total_acc= 50.05793742757822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c8c995e24743acaf664fceec66c973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:25', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 25, 'iter': 0, 'avg_loss': 6.720725059509277, 'avg_acc': 62.5, 'loss': 6.720725059509277}\n",
      "{'epoch': 25, 'iter': 400, 'avg_loss': 6.984578938852819, 'avg_acc': 49.906483790523694, 'loss': 6.9905314445495605}\n",
      "{'epoch': 25, 'iter': 800, 'avg_loss': 6.977122255627731, 'avg_acc': 50.156054931335824, 'loss': 6.74666690826416}\n",
      "\n",
      "EP25_train, avg_loss= 6.977926732994351 total_acc= 50.29037439762758\n",
      "EP:25 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc84e14d6d442a59a370695ae0d859a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:25', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 25, 'iter': 0, 'avg_loss': 7.13480281829834, 'avg_acc': 31.25, 'loss': 7.13480281829834}\n",
      "\n",
      "EP25_test, avg_loss= 7.048307043534738 total_acc= 50.57937427578216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8ebc2c480840189c6d5392907f5d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:26', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 26, 'iter': 0, 'avg_loss': 6.994550704956055, 'avg_acc': 62.5, 'loss': 6.994550704956055}\n",
      "{'epoch': 26, 'iter': 400, 'avg_loss': 6.9815287815959675, 'avg_acc': 49.781795511221944, 'loss': 6.900057792663574}\n",
      "{'epoch': 26, 'iter': 800, 'avg_loss': 6.971933288669467, 'avg_acc': 49.43039950062422, 'loss': 6.8859734535217285}\n",
      "\n",
      "EP26_train, avg_loss= 6.971016735427464 total_acc= 49.70962560237242\n",
      "EP:26 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac2705c11de40218efcbaaf7d47c318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:26', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 26, 'iter': 0, 'avg_loss': 7.154868125915527, 'avg_acc': 37.5, 'loss': 7.154868125915527}\n",
      "\n",
      "EP26_test, avg_loss= 7.010361053325512 total_acc= 50.405561993047506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef7b27db96745c4a83ce1d821fb5eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:27', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 27, 'iter': 0, 'avg_loss': 7.01690149307251, 'avg_acc': 62.5, 'loss': 7.01690149307251}\n",
      "{'epoch': 27, 'iter': 400, 'avg_loss': 6.97132545694746, 'avg_acc': 50.950748129675816, 'loss': 6.8730854988098145}\n",
      "{'epoch': 27, 'iter': 800, 'avg_loss': 6.969629462143306, 'avg_acc': 50.50717852684144, 'loss': 6.899282455444336}\n",
      "\n",
      "EP27_train, avg_loss= 6.969050401755473 total_acc= 50.72902508340541\n",
      "EP:27 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a76ed370d9347a79c21dff870203565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:27', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 27, 'iter': 0, 'avg_loss': 7.085572719573975, 'avg_acc': 31.25, 'loss': 7.085572719573975}\n",
      "\n",
      "EP27_test, avg_loss= 6.9962721621548685 total_acc= 49.53650057937428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0318cb2a953e443e8ed043588390849b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:28', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 28, 'iter': 0, 'avg_loss': 7.128693580627441, 'avg_acc': 62.5, 'loss': 7.128693580627441}\n",
      "{'epoch': 28, 'iter': 400, 'avg_loss': 6.970427924558112, 'avg_acc': 49.641521197007485, 'loss': 6.683968544006348}\n",
      "{'epoch': 28, 'iter': 800, 'avg_loss': 6.974428990658154, 'avg_acc': 49.71129837702871, 'loss': 6.890273094177246}\n",
      "\n",
      "EP28_train, avg_loss= 6.97911060845899 total_acc= 49.981465463981216\n",
      "EP:28 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a882443aa8c45b4b7aecab9a3e3ed56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:28', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 28, 'iter': 0, 'avg_loss': 7.051245212554932, 'avg_acc': 56.25, 'loss': 7.051245212554932}\n",
      "\n",
      "EP28_test, avg_loss= 6.977347921442102 total_acc= 49.71031286210892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef971ef4e8c434280d593b9fc3f5acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:29', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 29, 'iter': 0, 'avg_loss': 7.0379180908203125, 'avg_acc': 50.0, 'loss': 7.0379180908203125}\n",
      "{'epoch': 29, 'iter': 400, 'avg_loss': 6.965748430190241, 'avg_acc': 51.106608478803, 'loss': 7.111639499664307}\n",
      "{'epoch': 29, 'iter': 800, 'avg_loss': 6.968642589007127, 'avg_acc': 50.48377028714107, 'loss': 6.7342424392700195}\n",
      "\n",
      "EP29_train, avg_loss= 6.969449883393148 total_acc= 50.759915976770046\n",
      "EP:29 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed94a0e1e8f948a58887e3292ff4f7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:29', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 29, 'iter': 0, 'avg_loss': 7.0892863273620605, 'avg_acc': 68.75, 'loss': 7.0892863273620605}\n",
      "\n",
      "EP29_test, avg_loss= 6.943283014827305 total_acc= 49.94206257242178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf4332592ab49528546c0f928f22022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:30', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30, 'iter': 0, 'avg_loss': 7.023162364959717, 'avg_acc': 50.0, 'loss': 7.023162364959717}\n",
      "{'epoch': 30, 'iter': 400, 'avg_loss': 6.966954671236643, 'avg_acc': 49.73503740648379, 'loss': 6.906540870666504}\n",
      "{'epoch': 30, 'iter': 800, 'avg_loss': 6.9663079198677735, 'avg_acc': 49.39918851435706, 'loss': 6.690585136413574}\n",
      "\n",
      "EP30_train, avg_loss= 6.96869202800419 total_acc= 49.59841838625973\n",
      "EP:30 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb165bfa0e174781b67ce634ac5df864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:30', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30, 'iter': 0, 'avg_loss': 7.359606742858887, 'avg_acc': 75.0, 'loss': 7.359606742858887}\n",
      "\n",
      "EP30_test, avg_loss= 7.007091950487207 total_acc= 48.261877172653534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4920eb4208cb44f8889d4f577f1e64e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:31', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 31, 'iter': 0, 'avg_loss': 7.176765441894531, 'avg_acc': 37.5, 'loss': 7.176765441894531}\n",
      "{'epoch': 31, 'iter': 400, 'avg_loss': 6.960443939056777, 'avg_acc': 49.08042394014963, 'loss': 6.815739154815674}\n",
      "{'epoch': 31, 'iter': 800, 'avg_loss': 6.968026714229703, 'avg_acc': 49.812734082397, 'loss': 6.7573676109313965}\n",
      "\n",
      "EP31_train, avg_loss= 6.969021072029596 total_acc= 49.95057457061658\n",
      "EP:31 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f7d05a68d74f5abe849605ee7df437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:31', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 31, 'iter': 0, 'avg_loss': 7.07455587387085, 'avg_acc': 62.5, 'loss': 7.07455587387085}\n",
      "\n",
      "EP31_test, avg_loss= 6.98941441377004 total_acc= 50.81112398609502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54072ce7f40045cc9b551e9e943228b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:32', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 32, 'iter': 0, 'avg_loss': 7.0042266845703125, 'avg_acc': 50.0, 'loss': 7.0042266845703125}\n",
      "{'epoch': 32, 'iter': 400, 'avg_loss': 6.967139534224893, 'avg_acc': 50.14027431421446, 'loss': 6.715808391571045}\n",
      "{'epoch': 32, 'iter': 800, 'avg_loss': 6.966694219877359, 'avg_acc': 50.10923845193508, 'loss': 6.852078914642334}\n",
      "\n",
      "EP32_train, avg_loss= 6.967543139759259 total_acc= 49.81465463981218\n",
      "EP:32 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd01d626f1fe40c7999a7df662952e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:32', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 32, 'iter': 0, 'avg_loss': 6.860957622528076, 'avg_acc': 43.75, 'loss': 6.860957622528076}\n",
      "\n",
      "EP32_test, avg_loss= 7.0030082199308605 total_acc= 51.15874855156431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6102b7aa570f4e128c5edf470f25a7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:33', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 33, 'iter': 0, 'avg_loss': 6.934237957000732, 'avg_acc': 43.75, 'loss': 6.934237957000732}\n",
      "{'epoch': 33, 'iter': 400, 'avg_loss': 6.956319829175002, 'avg_acc': 49.95324189526185, 'loss': 6.824589252471924}\n",
      "{'epoch': 33, 'iter': 800, 'avg_loss': 6.961374984103047, 'avg_acc': 50.148252184769035, 'loss': 6.775905132293701}\n",
      "\n",
      "EP33_train, avg_loss= 6.964490994634365 total_acc= 49.97528728530829\n",
      "EP:33 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438a079f0866463b956c105677fc008c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:33', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 33, 'iter': 0, 'avg_loss': 7.210438251495361, 'avg_acc': 62.5, 'loss': 7.210438251495361}\n",
      "\n",
      "EP33_test, avg_loss= 7.072836129753678 total_acc= 50.05793742757822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf1fbd225d24c05a7a1582174819ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:34', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 34, 'iter': 0, 'avg_loss': 6.955696105957031, 'avg_acc': 56.25, 'loss': 6.955696105957031}\n",
      "{'epoch': 34, 'iter': 400, 'avg_loss': 6.963213594774356, 'avg_acc': 51.12219451371571, 'loss': 6.977696895599365}\n",
      "{'epoch': 34, 'iter': 800, 'avg_loss': 6.96332806624128, 'avg_acc': 50.273096129837704, 'loss': 6.8380303382873535}\n",
      "\n",
      "EP34_train, avg_loss= 6.960564059231121 total_acc= 50.661065118003215\n",
      "EP:34 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443e6a1ed4e54d45afbfac95cd4cffc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:34', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 34, 'iter': 0, 'avg_loss': 6.819902420043945, 'avg_acc': 43.75, 'loss': 6.819902420043945}\n",
      "\n",
      "EP34_test, avg_loss= 7.0418769518534345 total_acc= 50.05793742757822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d60ec54146148398bac6521ccd1946c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:35', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 35, 'iter': 0, 'avg_loss': 7.086144924163818, 'avg_acc': 37.5, 'loss': 7.086144924163818}\n",
      "{'epoch': 35, 'iter': 400, 'avg_loss': 6.9655280874257075, 'avg_acc': 50.46758104738155, 'loss': 6.869312286376953}\n",
      "{'epoch': 35, 'iter': 800, 'avg_loss': 6.969393696826645, 'avg_acc': 50.13264669163545, 'loss': 6.994606971740723}\n",
      "\n",
      "EP35_train, avg_loss= 6.966789033573136 total_acc= 49.85172371184974\n",
      "EP:35 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149796fc87bd4b40b9f365733ee97c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:35', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 35, 'iter': 0, 'avg_loss': 7.348604679107666, 'avg_acc': 50.0, 'loss': 7.348604679107666}\n",
      "\n",
      "EP35_test, avg_loss= 7.0306576313795865 total_acc= 49.76825028968714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e7fa2343254d618c7d40be657ac04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:36', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 36, 'iter': 0, 'avg_loss': 7.0608229637146, 'avg_acc': 87.5, 'loss': 7.0608229637146}\n",
      "{'epoch': 36, 'iter': 400, 'avg_loss': 6.9730816505793625, 'avg_acc': 50.857231920199496, 'loss': 7.193516731262207}\n",
      "{'epoch': 36, 'iter': 800, 'avg_loss': 6.967951806148191, 'avg_acc': 50.77247191011236, 'loss': 6.7061638832092285}\n",
      "\n",
      "EP36_train, avg_loss= 6.9690405997363 total_acc= 50.53132336587174\n",
      "EP:36 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4337481c6a4d33ae997e8ec0654d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:36', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 36, 'iter': 0, 'avg_loss': 6.9594035148620605, 'avg_acc': 68.75, 'loss': 6.9594035148620605}\n",
      "\n",
      "EP36_test, avg_loss= 7.04901608272835 total_acc= 50.28968713789108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99538621c364a80985908cb0e9719c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:37', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 37, 'iter': 0, 'avg_loss': 7.027158260345459, 'avg_acc': 50.0, 'loss': 7.027158260345459}\n",
      "{'epoch': 37, 'iter': 400, 'avg_loss': 6.962616718320775, 'avg_acc': 49.76620947630923, 'loss': 6.65673828125}\n",
      "{'epoch': 37, 'iter': 800, 'avg_loss': 6.966544611474846, 'avg_acc': 49.68008739076154, 'loss': 6.704526424407959}\n",
      "\n",
      "EP37_train, avg_loss= 6.96762216562339 total_acc= 49.96293092796244\n",
      "EP:37 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4940367065d44819a51011c857cefd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:37', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 37, 'iter': 0, 'avg_loss': 7.143213748931885, 'avg_acc': 31.25, 'loss': 7.143213748931885}\n",
      "\n",
      "EP37_test, avg_loss= 7.048581551622461 total_acc= 50.05793742757822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eee01cc17fc48f7afa4830de982f941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:38', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 38, 'iter': 0, 'avg_loss': 7.000029563903809, 'avg_acc': 31.25, 'loss': 7.000029563903809}\n",
      "{'epoch': 38, 'iter': 400, 'avg_loss': 6.9586111756037, 'avg_acc': 50.670199501246884, 'loss': 6.8773884773254395}\n",
      "{'epoch': 38, 'iter': 800, 'avg_loss': 6.962103363875295, 'avg_acc': 50.47596754057429, 'loss': 6.838382720947266}\n",
      "\n",
      "EP38_train, avg_loss= 6.966530566158974 total_acc= 50.07413814407513\n",
      "EP:38 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6238b3be17fc432ebdcc210ec35d4578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:38', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 38, 'iter': 0, 'avg_loss': 6.855334281921387, 'avg_acc': 50.0, 'loss': 6.855334281921387}\n",
      "\n",
      "EP38_test, avg_loss= 6.998677337611163 total_acc= 47.21900347624565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9caebcf1a6749368f3ea587baea1843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:39', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 39, 'iter': 0, 'avg_loss': 7.311832427978516, 'avg_acc': 43.75, 'loss': 7.311832427978516}\n",
      "{'epoch': 39, 'iter': 400, 'avg_loss': 6.962133044911145, 'avg_acc': 51.106608478803, 'loss': 7.025884628295898}\n",
      "{'epoch': 39, 'iter': 800, 'avg_loss': 6.964373590347918, 'avg_acc': 50.83489388264669, 'loss': 6.790438652038574}\n",
      "\n",
      "EP39_train, avg_loss= 6.9651682475809995 total_acc= 50.66724329667614\n",
      "EP:39 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8e4f37d7204b68a1d3c672f97d1438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:39', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 39, 'iter': 0, 'avg_loss': 6.99275541305542, 'avg_acc': 50.0, 'loss': 6.99275541305542}\n",
      "\n",
      "EP39_test, avg_loss= 7.031220656854135 total_acc= 48.95712630359212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6984ffc9b5a54648aee2f263e94b5a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:40', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 40, 'iter': 0, 'avg_loss': 7.037034034729004, 'avg_acc': 56.25, 'loss': 7.037034034729004}\n",
      "{'epoch': 40, 'iter': 400, 'avg_loss': 6.954881467129524, 'avg_acc': 49.8285536159601, 'loss': 7.023557662963867}\n",
      "{'epoch': 40, 'iter': 800, 'avg_loss': 6.9596838522493165, 'avg_acc': 49.51622971285893, 'loss': 6.935403347015381}\n",
      "\n",
      "EP40_train, avg_loss= 6.959512190856481 total_acc= 49.7961201037934\n",
      "EP:40 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0d0a73ff234b5ba2e394c317633bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:40', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 40, 'iter': 0, 'avg_loss': 6.748645782470703, 'avg_acc': 68.75, 'loss': 6.748645782470703}\n",
      "\n",
      "EP40_test, avg_loss= 6.993540463624178 total_acc= 49.015063731170336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b6a26dcd4b49c1ac195ebc17622e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:41', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 41, 'iter': 0, 'avg_loss': 7.10067081451416, 'avg_acc': 56.25, 'loss': 7.10067081451416}\n",
      "{'epoch': 41, 'iter': 400, 'avg_loss': 6.951927433584694, 'avg_acc': 51.07543640897756, 'loss': 7.134896755218506}\n",
      "{'epoch': 41, 'iter': 800, 'avg_loss': 6.952903955319103, 'avg_acc': 50.530586766541816, 'loss': 7.024403095245361}\n",
      "\n",
      "EP41_train, avg_loss= 6.957018188337092 total_acc= 50.50043247250711\n",
      "EP:41 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1203fb9cfa5a4633832e5e695abf04c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:41', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 41, 'iter': 0, 'avg_loss': 7.616061687469482, 'avg_acc': 56.25, 'loss': 7.616061687469482}\n",
      "\n",
      "EP41_test, avg_loss= 7.048428407421818 total_acc= 49.76825028968714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916394e988634dc08c108472d38bfbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:42', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 42, 'iter': 0, 'avg_loss': 7.004776477813721, 'avg_acc': 43.75, 'loss': 7.004776477813721}\n",
      "{'epoch': 42, 'iter': 400, 'avg_loss': 6.948425587870534, 'avg_acc': 49.329800498753116, 'loss': 6.966439247131348}\n",
      "{'epoch': 42, 'iter': 800, 'avg_loss': 6.953744641255201, 'avg_acc': 50.28089887640449, 'loss': 6.920934677124023}\n",
      "\n",
      "EP42_train, avg_loss= 6.958611568443389 total_acc= 50.15445446682318\n",
      "EP:42 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff61c27430874611afbc1f3dc6a31f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:42', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 42, 'iter': 0, 'avg_loss': 7.201807975769043, 'avg_acc': 56.25, 'loss': 7.201807975769043}\n",
      "\n",
      "EP42_test, avg_loss= 7.012172628332068 total_acc= 49.18887601390498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc536fec1cd4bfea08c6f3034c373e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:43', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 43, 'iter': 0, 'avg_loss': 7.173555850982666, 'avg_acc': 62.5, 'loss': 7.173555850982666}\n",
      "{'epoch': 43, 'iter': 400, 'avg_loss': 6.9538459742158425, 'avg_acc': 50.34289276807981, 'loss': 6.826233386993408}\n",
      "{'epoch': 43, 'iter': 800, 'avg_loss': 6.962406175711033, 'avg_acc': 49.74250936329588, 'loss': 6.495599269866943}\n",
      "\n",
      "EP43_train, avg_loss= 6.963141374437234 total_acc= 50.07413814407513\n",
      "EP:43 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcdd58c0ea34c9886fd66e5c406be73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:43', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 43, 'iter': 0, 'avg_loss': 7.395040512084961, 'avg_acc': 62.5, 'loss': 7.395040512084961}\n",
      "\n",
      "EP43_test, avg_loss= 7.042791693298905 total_acc= 52.95480880648899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384051eda7c24a239c448cc93b525245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:44', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 44, 'iter': 0, 'avg_loss': 6.964870452880859, 'avg_acc': 75.0, 'loss': 6.964870452880859}\n",
      "{'epoch': 44, 'iter': 400, 'avg_loss': 6.962821414643095, 'avg_acc': 49.4856608478803, 'loss': 7.011837959289551}\n",
      "{'epoch': 44, 'iter': 800, 'avg_loss': 6.956543962904874, 'avg_acc': 49.118289637952564, 'loss': 6.721404075622559}\n",
      "\n",
      "EP44_train, avg_loss= 6.957541454922069 total_acc= 49.06091684171506\n",
      "EP:44 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e7cae057b847ac8b25ec4722213850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:44', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 44, 'iter': 0, 'avg_loss': 6.837031841278076, 'avg_acc': 43.75, 'loss': 6.837031841278076}\n",
      "\n",
      "EP44_test, avg_loss= 7.013807822156836 total_acc= 50.28968713789108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6273b2b9193e4d89b07ec5e766255776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:45', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 45, 'iter': 0, 'avg_loss': 7.013490200042725, 'avg_acc': 56.25, 'loss': 7.013490200042725}\n",
      "{'epoch': 45, 'iter': 400, 'avg_loss': 6.960825923672341, 'avg_acc': 50.65461346633416, 'loss': 6.878565788269043}\n",
      "{'epoch': 45, 'iter': 800, 'avg_loss': 6.959553123264575, 'avg_acc': 50.90511860174781, 'loss': 6.881985664367676}\n",
      "\n",
      "EP45_train, avg_loss= 6.9601312593037905 total_acc= 50.71666872605956\n",
      "EP:45 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c57e32a7b449288f3e14010278a9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:45', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 45, 'iter': 0, 'avg_loss': 6.792926788330078, 'avg_acc': 37.5, 'loss': 6.792926788330078}\n",
      "\n",
      "EP45_test, avg_loss= 7.073917344764427 total_acc= 49.53650057937428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0b90bb2cc74cdda6483e2c9dc06a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:46', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 46, 'iter': 0, 'avg_loss': 7.117523193359375, 'avg_acc': 43.75, 'loss': 7.117523193359375}\n",
      "{'epoch': 46, 'iter': 400, 'avg_loss': 6.959465308676931, 'avg_acc': 49.220698254364095, 'loss': 6.811488628387451}\n",
      "{'epoch': 46, 'iter': 800, 'avg_loss': 6.960369824470206, 'avg_acc': 49.87515605493134, 'loss': 6.785155773162842}\n",
      "\n",
      "EP46_train, avg_loss= 6.96185373977239 total_acc= 50.29037439762758\n",
      "EP:46 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a444f84a1c4f4b90c68a5f63f7e405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:46', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 46, 'iter': 0, 'avg_loss': 7.497143745422363, 'avg_acc': 43.75, 'loss': 7.497143745422363}\n",
      "\n",
      "EP46_test, avg_loss= 7.02750661638048 total_acc= 50.405561993047506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1fa81521cf4b8ca55f3e0002ae6c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:47', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 47, 'iter': 0, 'avg_loss': 7.241518497467041, 'avg_acc': 56.25, 'loss': 7.241518497467041}\n",
      "{'epoch': 47, 'iter': 400, 'avg_loss': 6.9618441386710375, 'avg_acc': 49.298628428927685, 'loss': 6.950791358947754}\n",
      "{'epoch': 47, 'iter': 800, 'avg_loss': 6.95797583345468, 'avg_acc': 49.86735330836454, 'loss': 6.904091835021973}\n",
      "\n",
      "EP47_train, avg_loss= 6.961702972532732 total_acc= 49.95675274928951\n",
      "EP:47 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6cab8c5f4745e1ab93dc0fbdc4afb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:47', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 47, 'iter': 0, 'avg_loss': 7.258745193481445, 'avg_acc': 43.75, 'loss': 7.258745193481445}\n",
      "\n",
      "EP47_test, avg_loss= 7.033828130474797 total_acc= 51.04287369640788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91565e8cd2cf40068f7f90ea5700dd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:48', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 48, 'iter': 0, 'avg_loss': 7.073668479919434, 'avg_acc': 43.75, 'loss': 7.073668479919434}\n",
      "{'epoch': 48, 'iter': 400, 'avg_loss': 6.947320022487879, 'avg_acc': 50.45199501246883, 'loss': 6.977117538452148}\n",
      "{'epoch': 48, 'iter': 800, 'avg_loss': 6.954043479447954, 'avg_acc': 50.218476903870155, 'loss': 6.887017250061035}\n",
      "\n",
      "EP48_train, avg_loss= 6.956282810260185 total_acc= 49.993821821327074\n",
      "EP:48 Model Saved on: ./models/bert_02_small.{}.ep{:02d}.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0001530724294ea6893f2ade2edc65d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_test:48', max=108.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 48, 'iter': 0, 'avg_loss': 6.997890472412109, 'avg_acc': 43.75, 'loss': 6.997890472412109}\n",
      "\n",
      "EP48_test, avg_loss= 7.0191180485266225 total_acc= 49.594438006952494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8c2d0f99344b60ba933b9cc08bb6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EP_train:49', max=1012.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 49, 'iter': 0, 'avg_loss': 7.003330230712891, 'avg_acc': 50.0, 'loss': 7.003330230712891}\n",
      "{'epoch': 49, 'iter': 400, 'avg_loss': 6.947207901543216, 'avg_acc': 50.29613466334164, 'loss': 6.854007720947266}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-36e946b72c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-7d6b95b280aa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-7d6b95b280aa>\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, epoch, data_loader, train)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_and_update_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/main/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/main/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_start = 0\n",
    "print(\"Training Start\")\n",
    "for epoch in range(epoch_start, epochs + epoch_start):\n",
    "    trainer.train(epoch)\n",
    "    trainer.save(epoch, output_path)\n",
    "\n",
    "    if test_data_loader is not None:\n",
    "        trainer.test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:2 Model Saved on: ./models/bert_01.{0}.ep{1:2d}.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./models/bert_01.{0}.ep{1:2d}.pt'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.save(2, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. BERT for Named-Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BERT model\n"
     ]
    }
   ],
   "source": [
    "print(\"Building BERT model\")\n",
    "bert = BERT(len(vocab), hidden=hidden, n_layers=layers, attn_heads=attn_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.load_state_dict(torch.load(\"./models/bert_01.bert.statedict.ep02.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_dataset[3]\n",
    "inputs = {key: value.to('cuda') for key, value in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.model(inputs['bert_input'].unsqueeze(0), inputs['segment_label'].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [UNK] [MASK] with positive sales in [UNK] , and was praised by both [UNK] and western critics . [UNK] release , it received downloadable content , [MASK] with an expanded edition in [UNK] of that year . [UNK] was [MASK] adapted ##gan manga and an original video animation series . [UNK] [MASK] low sales of [UNK] [UNK] [UNK] , [UNK] [UNK] [UNK] was not localized , but a fan translation compatible with the game [UNK] expanded edition was released in [MASK] . [UNK] would return to the franchise with the [MASK] of [UNK] : [UNK] [UNK] for the [UNK] 4 . \n",
      "\n",
      "\n",
      "\n",
      " [UNK] [UNK] travelled to the [UNK] [UNK] in [UNK] 2009 , to commence work on their seventh studio album , [UNK] 7 . [MASK] [MASK] a contract [MASK] [UNK] [UNK] [UNK] [UNK] label , [UNK] [UNK] , [MASK] in collaborations with [MASK] [UNK] profile producers . [UNK] late [UNK] 2009 , the [MASK] [MASK] [MASK] [MASK] were working with [UNK] [UNK] , known by his stage name [MASK] , on two songs . [UNK] [UNK] a [UNK] [UNK] was lice and produced by [UNK] , who ##teen the 2nd in collaboration with [UNK] [UNK] . [UNK] song [MASK] recorded lae [UNK] [UNK] in [UNK] [UNK] , [UNK] . [UNK] was mixed by [UNK] [UNK] [UNK] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in \" \".join([vocab.itos[t] for t in inputs['bert_input'].cpu().tolist() if t!=0]).split(\"[SEP]\"):\n",
    "    print(sent)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"is_next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-18.5915,   0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
